\documentclass[12pt]{article}
\usepackage{adi}

\title{DRP: Fourier Analysis on Groups}
\author{Adithya Ganesh}
\begin{document}
\maketitle
\section{Introduction to Finite Markov Chains}

A finite Markov chain is a process which moves among the elements of a finite set $\Omega$ in the following manner: when at $x \in \Omega$, the next position is chosen according to a fixed probability distribution $P(x, \cdot)$.

(More formal definition.)

\begin{theorem}

\end{theorem}

\begin{definition}
  For $x \in \Omega$, define the {\bf hitting time} for $x$ to be
  \begin{align*}
    \tau_x := \min \left\{ t \geq 0, X_t = x \right\},
  \end{align*}
  that is, the first time at which the chain visits state $x$.

  \section{Meeting 1}

  $s_0, \dots, s_n$ family of random variables. $\mathcal{F}_i$ is the filtration at time $i$, which is equal to $\sigma(s_0, s_1, \dots, s_i)$, the signal algebra generated by $s_0, \dots, s_i$.

  A probability space is a given of three things:
  \begin{align*}
    (\Omega, \mathcal{F}, p),
  \end{align*}
  where $\Omega$ is the state space, $\mathcal{F}$ is a sigma-algebra, and $p$ is a prob measures

  When $\mathcal{F}$ is the power set in the discrete case.  The $\sigma$ algebra is a collection $C$ of subsets such that
  \begin{itemize}
    \item $\emptyset \in C$.
    \item $A \in C \implies A^C \in C$.
    \item $A_1, A_2, \dots, A_n \in C \implies \bigcup A_i \in C$.
  \end{itemize}

  A probability measure is a function $p: \mathcal{F} \to [0, 1]$ such that
  \begin{itemize}
    \item $p(\emptyset) = 0$
    \item  $p(\bigcup_{i=1}^{\infty} A_i) = \sum_{i=1}^{\infty} P(A_i) $ if $A_i \cap A_j \neq \emptyset$.
  \end{itemize}

  Why sigma algebras?  Consider a sequence of $n$ coin tosses.  We can write
  \begin{align*}
    (\Omega, \mathcal{F}, p) = \left( \left\{ 0, 1 \right\}^n, 2^\left\{ {0, 1 \right\}^n}, p = \text{uniform} \right).
  \end{align*}

  In the continuous case,  $(\Omega, \mathcal{F}, p)$, $\Omega = [0, 1]$, where $p = $ uniform measure, $p\left( (a, b) \right) = b-a$.

  \begin{definition}
    Martingales.
  \end{definition}

  \begin{definition}
    If $\FF$ is a $\sigma$-algebra, $X$ is an RV, then
    \begin{align*}
      \EE [X | \FF] 
    \end{align*}
    is the unique rv s.t.
    \begin{align*}
      \EE [X 1_A] = \EE\left[  \EE \left[ x | \FF \right] 1_A \right],
    \end{align*}
    for all $A \in \FF$.
  \end{definition}
\end{definition}

Let $T =$ stopping time, which is the property that
\begin{align*}
  \left\{ T \leq n \right\} \in \mathcal{F}_n = \sigma(S_0, \dots, S_n).
\end{align*}

The optimal stopping theorem states that
\begin{align*}
  \EE\left[ S_T \right] = 0,
\end{align*}
if $S_{\min(N, T}$ is bounded.

  The Gambler's problem is a martingale.
  \begin{align*}
    \EE\left[ S_T \right] = 0,
  \end{align*}
  so
  \begin{align*}
    P(S_T = -b)(-b) + P(S_T = a) a = 0,
  \end{align*}
  so $p = \frac{b}{a+b}$.

  {\bf Exercise.} Gambler ruin with bias. Suppose $S_n = X_1 + X_2 + \dots + X_n$, $\EE[X_i] = p < 0$.

\end{document}
